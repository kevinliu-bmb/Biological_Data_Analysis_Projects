{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f075599",
   "metadata": {},
   "source": [
    "## Homework 02: The Adventure of the Ten Arcs\n",
    "##### By Kevin Liu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba11f966",
   "metadata": {},
   "source": [
    "Before we begin, we will first import the neccessary libraries and define the parameters for the Arc locus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "968fa646",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "experiment = 0 # if 0, run simulation using original parameters; if 1, run using experiment 1 parameters; if 2, run using experiment 2 parameters.\n",
    "\n",
    "# Set up the Arc locus \n",
    "S         = 10           # Number of segments in the Arc locus (A..J)\n",
    "T         = S            # Number of different transcripts (the same, one starting on each segment, 1..10)\n",
    "N         = 100000       # total number of observed reads we generate\n",
    "len_S     = 1000         # length of each segment (nucleotides)\n",
    "len_Arc   = len_S * S    # total length of the Arc locus (nucleotides)\n",
    "len_R     = 75           # read length\n",
    "\n",
    "if experiment == 0:\n",
    "    segment_map = {'Arc1': ['A', 'B', 'C', 'D'], \n",
    "               'Arc2': ['B', 'C'],\n",
    "              'Arc3': ['C', 'D', 'E'],\n",
    "              'Arc4': ['D', 'E', 'F', 'G'], \n",
    "              'Arc5': ['E', 'F', 'G', 'H'],\n",
    "              'Arc6': ['F', 'G', 'H'],\n",
    "              'Arc7': ['G', 'H'],\n",
    "              'Arc8': ['H', 'I'],\n",
    "              'Arc9': ['I', 'J', 'A'],\n",
    "              'Arc10': ['J', 'A', 'B']}\n",
    "    arc_nu = {'Arc1': 0.008, \n",
    "              'Arc2': 0.039,\n",
    "              'Arc3': 0.291,\n",
    "              'Arc4': 0.112, \n",
    "              'Arc5': 0.127,\n",
    "              'Arc6': 0.008,\n",
    "              'Arc7': 0.059,\n",
    "              'Arc8': 0.060,\n",
    "              'Arc9': 0.022,\n",
    "              'Arc10': 0.273}\n",
    "elif experiment == 1:\n",
    "    segment_map = {'Arc1': ['A', 'B', 'C', 'D'], \n",
    "                   'Arc2': ['B', 'C'],\n",
    "                   'Arc3': ['C', 'D', 'E'],\n",
    "                   'Arc4': ['D', 'E', 'F', 'G'], \n",
    "                   'Arc5': ['E', 'F', 'G', 'H'],\n",
    "                   'Arc6': ['F', 'G', 'H'],\n",
    "                   'Arc7': ['G', 'H'],\n",
    "                   'Arc8': ['H', 'I']}\n",
    "    arc_nu = {}\n",
    "    for i in range(len(segment_map.keys())):\n",
    "        arc_nu['Arc'+str(i+1)] = np.random.dirichlet(np.ones(len(segment_map.keys())),size=1).tolist()[0][i]\n",
    "else:\n",
    "    segment_map = {'Arc1': ['A', 'B'], \n",
    "                   'Arc2': ['B', 'C'],\n",
    "                   'Arc3': ['C', 'D'],\n",
    "                   'Arc4': ['D', 'E'], \n",
    "                   'Arc5': ['E', 'F'],\n",
    "                   'Arc6': ['F', 'G'],\n",
    "                   'Arc7': ['G', 'H'],\n",
    "                   'Arc8': ['H', 'I'], \n",
    "                   'Arc9': ['I', 'J'],\n",
    "                   'Arc10': ['J', 'A']}\n",
    "    arc_nu = {'Arc1': 0.008, \n",
    "              'Arc2': 0.039,\n",
    "              'Arc3': 0.291,\n",
    "              'Arc4': 0.112, \n",
    "              'Arc5': 0.127,\n",
    "              'Arc6': 0.008,\n",
    "              'Arc7': 0.059,\n",
    "              'Arc8': 0.060,\n",
    "              'Arc9': 0.022,\n",
    "              'Arc10': 0.273}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d4464e",
   "metadata": {},
   "source": [
    "#### 1. Use kallisto and reproduce Moriarty's result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbef3a9",
   "metadata": {},
   "source": [
    "To replicate the result produced by Moriarty using Kallisto, we will first build a Kallisto index file using our Arc locus transcripts fasta file and then quantify the read abundances using our reads fastq file and the produced index file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7425433d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "[build] loading fasta file arc.fasta.gz\r\n",
      "[build] k-mer length: 31\r\n",
      "[build] counting k-mers ... done.\r\n",
      "[build] building target de Bruijn graph ...  done \r\n",
      "[build] creating equivalence classes ...  done\r\n",
      "[build] target de Bruijn graph has 19 contigs and contains 10000 k-mers \r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "! kallisto index -i arc.idx arc.fasta.gz # generate hash table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57f1458d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[quant] fragment length distribution is truncated gaussian with mean = 150, sd = 20\n",
      "[index] k-mer length: 31\n",
      "[index] number of targets: 10\n",
      "[index] number of k-mers: 10,000\n",
      "[index] number of equivalence classes: 26\n",
      "[quant] running in single-end mode\n",
      "[quant] will process file 1: arc.fastq.gz\n",
      "[quant] finding pseudoalignments for the reads ... done\n",
      "[quant] processed 100,000 reads, 99,981 reads pseudoaligned\n",
      "[   em] quantifying the abundances ... done\n",
      "[   em] the Expectation-Maximization algorithm ran for 81 rounds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! kallisto quant -i arc.idx -o arc_quant_out --single -l 150 -s 20 arc.fastq.gz # run quantification algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f448da",
   "metadata": {},
   "source": [
    "Next, we will examine the read abundance results produced by Kallisto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14893a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target_id  length     eff_length est_counts tpm       \n",
      "Arc1       4000.0     3851.0     2781.96    20318.9   \n",
      "Arc2       2000.0     1851.0     3585.12    54477.8   \n",
      "Arc3       3000.0     2851.0     28613.5    282290.0  \n",
      "Arc4       4000.0     3851.0     10412.4    76050.3   \n",
      "Arc5       4000.0     3851.0     13042.9    95263.0   \n",
      "Arc6       3000.0     2851.0     1195.26    11792.0   \n",
      "Arc7       2000.0     1851.0     5864.45    89113.5   \n",
      "Arc8       2000.0     1851.0     5717.54    86881.2   \n",
      "Arc9       3000.0     2851.0     2909.53    28704.4   \n",
      "Arc10      3000.0     2851.0     25858.3    255109.0  \n"
     ]
    }
   ],
   "source": [
    "# read in the abundance file generated by Kallisto.\n",
    "arc_abund = {}\n",
    "with open('arc_quant_out/abundance.tsv') as f:\n",
    "    next(f)\n",
    "    for line in f:\n",
    "        line = line.rstrip('\\n')\n",
    "        fields = line.split('\\t')\n",
    "        arc_abund[fields[0]] = [float(s) for s in fields[1:]]\n",
    "\n",
    "# print the names of the columns.\n",
    "strFormat = '{:<10} {:<10} {:<10} {:<10} {:<10}'\n",
    "print(strFormat.format('target_id', 'length', 'eff_length', 'est_counts', 'tpm'))\n",
    "\n",
    "# print each field from Kallisto output.\n",
    "for arc_n, prop in arc_abund.items():\n",
    "    tempList = [arc_n]\n",
    "    for i in range(len(prop)):\n",
    "        tempList.append(prop[i])\n",
    "    print(strFormat.format(*tempList))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a79dffa",
   "metadata": {},
   "source": [
    "The TPM values produced by Kallisto closely matches that of Moriarty's attempt and we have successfully reproduced their results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd06b11",
   "metadata": {},
   "source": [
    "#### 2a. Simulate an Arc transcriptome and RNA-seq reads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e045397f",
   "metadata": {},
   "source": [
    "Due to the discrepancies between the result produced by Kallisto and our own calculations, we will begin by generating simulated data according to the known Arc locus structure and its transcripts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44093603",
   "metadata": {},
   "source": [
    "We will first generate the Arc locus DNA sequence. Given the known length of the Arc locus, the length of each segment, and the total number of segments, we can construct a simulated Arc locus DNA with uniform base composition using randomly selected nucleotides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30a69ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate Arc locus DNA sequence.\n",
    "n_segments = [i.upper() for i in list(map(chr, range(97, 97+S)))] # Generate a list of the segments in Python with map and chr\n",
    "\n",
    "# make dictionary with keys from A-Z depending on S and list values as random DNA sequence of length len_S.\n",
    "arc_locus = {}\n",
    "for i in range(S):\n",
    "    arc_locus[n_segments[i]] = [np.random.choice(['A', 'T', 'G', 'C']) for i in range(len_S)]\n",
    "\n",
    "# check if total length is = N.\n",
    "# check_len = {}\n",
    "# for i in range(S):\n",
    "#     check_len[n_segments[i]] = ''.join(arc_locus[n_segments[i]])\n",
    "# print(len(''.join(check_len.values())) == len_Arc)\n",
    "\n",
    "arc_segment_list = []\n",
    "for i in n_segments:\n",
    "    arc_segment_list.append(''.join(''.join(arc_locus[i])))\n",
    "arc_locus_flat = ''.join(arc_segment_list)\n",
    "arc_locus_list = [*arc_locus_flat]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e0cd30",
   "metadata": {},
   "source": [
    "Since we know the segment composition for each of the Arc mRNA transcripts, we can then use the previously generated Arc locus DNA and the map of segments to each of the transcripts to construct each of the 10 Arc transcripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f776e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate Arc1...Arc10 mRNA transcripts.\n",
    "transcripts = {}\n",
    "for arc_n, segment_list in segment_map.items():\n",
    "    tempList = []\n",
    "    for segment in segment_list:\n",
    "        tempList.append(''.join(arc_locus[segment]))\n",
    "    transcripts[arc_n] = ''.join(tempList)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bc961b",
   "metadata": {},
   "source": [
    "These produced transcripts can then be written out as a fasta file that is compatible with Kallisto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7286753b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cut sequences into 60nt per line according to fasta format.\n",
    "transcripts_n60 = {}\n",
    "for arc_n, seq in transcripts.items():\n",
    "    transcripts_n60[arc_n] = [transcripts[arc_n][i:i+60] for i in range(0, len(transcripts[arc_n]), 60)]\n",
    "\n",
    "# write out transcripts as fasta file.\n",
    "with open('LiuKevin_02_2a.fasta', 'w') as f:\n",
    "    for arc_n, seq_lines in transcripts_n60.items():\n",
    "        f.write('>' + arc_n + '\\n')\n",
    "        for line in seq_lines:\n",
    "            f.write(line + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8304ef73",
   "metadata": {},
   "source": [
    "Lastly, we can generate simulated reads from each of the Arc mRNA transcripts with amounts that are determined by the abundances calculated in our own experiement. These generated reads can then be written out as a fastq file that is compatible with Kallisto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7d116e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate reads.\n",
    "# make dictionary for each transcript of n out of N total number of reads each with length len_R.\n",
    "n_reads = {}\n",
    "for arc_n, prop in arc_nu.items():\n",
    "    n_reads[arc_n] = int(N * prop)\n",
    "\n",
    "reads = {}\n",
    "for arc_n, n in n_reads.items():\n",
    "    read_seq = []\n",
    "    for i in range(n):\n",
    "        start_pos = np.random.randint(0, len(transcripts[arc_n])-75)\n",
    "        end_pos = start_pos + len_R\n",
    "        read_seq.append(transcripts[arc_n][start_pos:end_pos])\n",
    "    reads[arc_n] = read_seq\n",
    "\n",
    "# write out reads as fastq file.\n",
    "readsList = []\n",
    "for arc_n, readList in reads.items():\n",
    "    for n_read in readList:\n",
    "        readsList.append(n_read)\n",
    "\n",
    "with open('LiuKevin_02_2a.fastq', 'w') as f:\n",
    "    for read_i in range(len(readsList)):\n",
    "        headerLine = '@read' + str(read_i) + '\\n'\n",
    "        readLine = readsList[read_i] + '\\n'\n",
    "        plusLine = '+' + '\\n'\n",
    "        qLine = 'I' * len_R + '\\n'\n",
    "        f.write(headerLine + readLine + plusLine + qLine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bdd0a0",
   "metadata": {},
   "source": [
    "#### 3. Test kallisto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8807ab14",
   "metadata": {},
   "source": [
    "Since we have simulated our Arc locus transcripts and reads based on the abundances calculated by ourselves, lets run the simulated data through Kallisto to see if Kallisto's results would match our own calculations of TPM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e05299f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "[build] loading fasta file LiuKevin_02_2a.fasta\r\n",
      "[build] k-mer length: 31\r\n",
      "[build] counting k-mers ... done.\r\n",
      "[build] building target de Bruijn graph ...  done \r\n",
      "[build] creating equivalence classes ...  done\r\n",
      "[build] target de Bruijn graph has 19 contigs and contains 10000 k-mers \r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "! kallisto index -i synth_arc.idx LiuKevin_02_2a.fasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b43f7f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[quant] fragment length distribution is truncated gaussian with mean = 75, sd = 10\n",
      "[index] k-mer length: 31\n",
      "[index] number of targets: 10\n",
      "[index] number of k-mers: 10,000\n",
      "[index] number of equivalence classes: 26\n",
      "[quant] running in single-end mode\n",
      "[quant] will process file 1: LiuKevin_02_2a.fastq\n",
      "[quant] finding pseudoalignments for the reads ... done\n",
      "[quant] processed 99,899 reads, 99,899 reads pseudoaligned\n",
      "[   em] quantifying the abundances ... done\n",
      "[   em] the Expectation-Maximization algorithm ran for 55 rounds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! kallisto quant -i synth_arc.idx -o synth_arc_quant_out --single -l 75 -s 10 LiuKevin_02_2a.fastq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243a6126",
   "metadata": {},
   "source": [
    "Given that the simulated reads were produced based on a list of known nucleotide abundances for each transcript, we can calculate the transcript abundances based on nucleotide abundances and the effective length reported in Kallisto's results and compare them to the transcript abundances Kallisto produced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01ce10d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target_id  length     eff_length est_counts tpm        nu_i       calc_tpm   percent_diff\n",
      "Arc1       4000.0     3926.0     3254.54    24096.5    0.008      5856.18    1.22      \n",
      "Arc2       2000.0     1926.0     3179.01    47978.8    0.039      58194.65   0.19      \n",
      "Arc3       3000.0     2926.0     28697.0    285086.0   0.291      285820.53  0.00      \n",
      "Arc4       4000.0     3926.0     10122.5    74946.3    0.112      81986.53   0.09      \n",
      "Arc5       4000.0     3926.0     12589.5    93212.2    0.127      92966.86   0.00      \n",
      "Arc6       3000.0     2926.0     2219.1     22045.3    0.008      7857.61    0.95      \n",
      "Arc7       2000.0     1926.0     5520.61    83319.2    0.059      88038.06   0.06      \n",
      "Arc8       2000.0     1926.0     5506.19    83101.4    0.060      89530.23   0.07      \n",
      "Arc9       3000.0     2926.0     2957.45    29380.3    0.022      21608.43   0.30      \n",
      "Arc10      3000.0     2926.0     25853.1    256834.0   0.273      268140.91  0.04      \n"
     ]
    }
   ],
   "source": [
    "synth_arc_abund = {}\n",
    "with open('synth_arc_quant_out/abundance.tsv') as f:\n",
    "    next(f)\n",
    "    for line in f:\n",
    "        line = line.rstrip('\\n')\n",
    "        fields = line.split('\\t')\n",
    "        synth_arc_abund[fields[0]] = [float(s) for s in fields[1:]]\n",
    "\n",
    "# calculate tpm using known nu_i\n",
    "for arc_n, props in synth_arc_abund.items():\n",
    "    props.append(arc_nu[arc_n])\n",
    "\n",
    "for arc_n, prop in synth_arc_abund.items():\n",
    "    prop.append(synth_arc_abund[arc_n][4]/synth_arc_abund[arc_n][1])\n",
    "\n",
    "norm_vals = []\n",
    "for arc_n, props in synth_arc_abund.items():\n",
    "    norm_vals.append(props[5])\n",
    "\n",
    "norm_constant = 1/sum(norm_vals)\n",
    "\n",
    "for arc_n, prop in synth_arc_abund.items():\n",
    "    prop[5] = prop[5]*norm_constant*(10**6)  \n",
    "    prop.append(np.abs(prop[5]-prop[3])/((prop[5]+prop[3])/2))\n",
    "\n",
    "# Print the names of the columns.\n",
    "strFormat = '{:<10} {:<10} {:<10} {:<10} {:<10} {:<10} {:<10} {:<10}'\n",
    "numFormat = '{:<10} {:<10} {:<10} {:<10} {:<10} {:<10.3f} {:<10.2f} {:<10.2f}'\n",
    "print(strFormat.format('target_id', 'length', 'eff_length', 'est_counts', 'tpm', 'nu_i', 'calc_tpm', 'percent_diff'))\n",
    "\n",
    "# print each data item.\n",
    "for arc_n, prop in synth_arc_abund.items():\n",
    "    tempList = [arc_n]\n",
    "    for i in range(len(prop)):\n",
    "        tempList.append(prop[i])\n",
    "    print(numFormat.format(*tempList))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19b7d47",
   "metadata": {},
   "source": [
    "Given that the percent differences between the calculated transcript abundances and those produced by Kallisto for Arc1 and Arc6 are large, it is clear that the discrepancy between Kallisto results and our own results must be related to how Kallisto works on our specific data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1056f331",
   "metadata": {},
   "source": [
    "#### 4. \"Debug\" kallisto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13f4a40",
   "metadata": {},
   "source": [
    "##### Experiment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67b19f0",
   "metadata": {},
   "source": [
    "We first hypothesize that Kallisto only works on reads from a linear locus, whereas Arc has a circular locus. Therefore, it is expected that the resulting transcript abundances between our original approach and Moriarty's Kallisto approach do not correspond.\n",
    "\n",
    "To test this first hypothesis, we can perform an experiment by assuming that the Arc locus has a linear structure as opposed to its circular structure. To do this, we will discard the Arc9 and Arc10 transcripts because they span the circular linking region of the locus as well as their associated reads from our simulated data. Furthermore, we will randomly generate nucleotide abundances for each Arc transcript and use them to calculate the transcript abundances for comparison with what Kallisto generates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593be3b3",
   "metadata": {},
   "source": [
    "**Please set <experiment = 1> in the code chunk that defines all parameters for the Arc locus (top of the notebook) and re-run the whole notebook to produce results that test our hypothesis.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63286df1",
   "metadata": {},
   "source": [
    "After carrying out our first experiment using the newly simulated data, we find that the percent differences between the transcript abundances produced by Kallisto and our own calculations remain fairly large for Arc6. This does not match our expectations as it suggests that the circular locus structure of Arc can be resolved by Kallisto and that the discrepancy arises from some other source."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0988bd",
   "metadata": {},
   "source": [
    "##### Experiment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d84d8fa",
   "metadata": {},
   "source": [
    "Since the previous experiment has yielded unsatisfactory results that contradicts our first hypothesis, we will explore the nature of the Arc transcripts further. We notice that the sequence for transcript Arc2 is contained within the sequence for Arc1 and the sequences for Arc6 and Arc7 are contained within the sequence for Arc5. Therefore, we then hypothesize that Kallisto might have erroneously mapped the reads for those transcripts contained within other transcripts. We will then conduct a second experiment using non-overlapping transcript definitions to test our hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26b6cca",
   "metadata": {},
   "source": [
    "**Please set <experiment = 2> in the code chunk that defines all parameters for the Arc locus (top of the notebook) and re-run the whole notebook to produce results that test our hypothesis.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18390a18",
   "metadata": {},
   "source": [
    "Following our second experiment, we notice that the calculated percent differences are much lower than the original experimental conditions and our first experiment. This suggests that our second experiment supports our hypothesis that the discrepancies between our original results and Moriarty's results are likely due to Kallisto's erroneous mapping of reads from overlapping transcripts."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
